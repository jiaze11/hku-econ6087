{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Text Vectorization and Supervised Learning (English)\n",
    "\n",
    "Working with the `ag_news` dataset — news articles categorized into four topics:\n",
    "- World (0)\n",
    "- Sports (1)\n",
    "- Business (2)\n",
    "- Sci/Tech (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data Preparation\n",
    "\n",
    "Load the `ag_news` dataset from Hugging Face and convert to pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 120000\n",
      "Testing set size:  7600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...      2\n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n",
       "4  Oil prices soar to all-time record, posing new...      2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ag_news\")\n",
    "\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "test_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Testing set size:  {len(test_df)}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2(a) Preprocessing\n",
    "\n",
    "- Convert to lowercase\n",
    "- Remove punctuation and special characters\n",
    "- Remove standard English stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "      <td>wall st bears claw back into the black reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>carlyle looks toward commercial aerospace reut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>oil and economy cloud stocks outlook reuters r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>iraq halts oil exports from main southern pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>oil prices soar to all time record posing new ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...   \n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...   \n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                               clean  \n",
       "0  wall st bears claw back into the black reuters...  \n",
       "1  carlyle looks toward commercial aerospace reut...  \n",
       "2  oil and economy cloud stocks outlook reuters r...  \n",
       "3  iraq halts oil exports from main southern pipe...  \n",
       "4  oil prices soar to all time record posing new ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text: str) -> str:\n",
    "    \"\"\"Lowercase, strip punctuation/special chars, collapse whitespace.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "train_df[\"clean\"] = train_df[\"text\"].apply(preprocess)\n",
    "test_df[\"clean\"] = test_df[\"text\"].apply(preprocess)\n",
    "\n",
    "train_df[[\"text\", \"clean\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2(b) Vectorization — Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW dictionary size: 61488\n",
      "\n",
      "Top 10 words (BoW):\n",
      "  1. new  (count: 21428)\n",
      "  2. said  (count: 20267)\n",
      "  3. reuters  (count: 19340)\n",
      "  4. ap  (count: 16277)\n",
      "  5. gt  (count: 13239)\n",
      "  6. lt  (count: 13183)\n",
      "  7. year  (count: 9773)\n",
      "  8. quot  (count: 9596)\n",
      "  9. world  (count: 8634)\n",
      "  10. company  (count: 7656)\n"
     ]
    }
   ],
   "source": [
    "bow_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "X_train_bow = bow_vectorizer.fit_transform(train_df[\"clean\"])\n",
    "X_test_bow = bow_vectorizer.transform(test_df[\"clean\"])\n",
    "\n",
    "bow_vocab = bow_vectorizer.get_feature_names_out()\n",
    "print(f\"BoW dictionary size: {len(bow_vocab)}\")\n",
    "\n",
    "# Top 10 most frequent words in the training corpus\n",
    "bow_word_counts = X_train_bow.sum(axis=0).A1  # dense 1-d array\n",
    "top10_bow_idx = bow_word_counts.argsort()[::-1][:10]\n",
    "print(\"\\nTop 10 words (BoW):\")\n",
    "for rank, idx in enumerate(top10_bow_idx, 1):\n",
    "    print(f\"  {rank}. {bow_vocab[idx]}  (count: {int(bow_word_counts[idx])})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2(b) Vectorization — TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF dictionary size: 61488\n",
      "\n",
      "Top 10 words (TF-IDF):\n",
      "  1. new  (total weight: 1653.94)\n",
      "  2. reuters  (total weight: 1576.99)\n",
      "  3. ap  (total weight: 1559.36)\n",
      "  4. said  (total weight: 1489.33)\n",
      "  5. gt  (total weight: 1163.33)\n",
      "  6. lt  (total weight: 1160.21)\n",
      "  7. quot  (total weight: 1030.11)\n",
      "  8. year  (total weight: 958.83)\n",
      "  9. oil  (total weight: 924.37)\n",
      "  10. world  (total weight: 887.45)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"clean\"])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df[\"clean\"])\n",
    "\n",
    "tfidf_vocab = tfidf_vectorizer.get_feature_names_out()\n",
    "print(f\"TF-IDF dictionary size: {len(tfidf_vocab)}\")\n",
    "\n",
    "# Top 10 words by total TF-IDF weight across training corpus\n",
    "tfidf_word_weights = X_train_tfidf.sum(axis=0).A1\n",
    "top10_tfidf_idx = tfidf_word_weights.argsort()[::-1][:10]\n",
    "print(\"\\nTop 10 words (TF-IDF):\")\n",
    "for rank, idx in enumerate(top10_tfidf_idx, 1):\n",
    "    print(f\"  {rank}. {tfidf_vocab[idx]}  (total weight: {tfidf_word_weights[idx]:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2(c) Modeling — Logistic Regression with BoW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BoW + Logistic Regression ===\n",
      "Training accuracy: 0.9779\n",
      "Testing accuracy:  0.9070\n"
     ]
    }
   ],
   "source": [
    "y_train = train_df[\"label\"]\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "clf_bow = LogisticRegression(max_iter=1000, random_state=RANDOM_SEED)\n",
    "clf_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "bow_train_acc = accuracy_score(y_train, clf_bow.predict(X_train_bow))\n",
    "bow_test_acc = accuracy_score(y_test, clf_bow.predict(X_test_bow))\n",
    "\n",
    "print(\"=== BoW + Logistic Regression ===\")\n",
    "print(f\"Training accuracy: {bow_train_acc:.4f}\")\n",
    "print(f\"Testing accuracy:  {bow_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2(c) Modeling — Logistic Regression with TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TF-IDF + Logistic Regression ===\n",
      "Training accuracy: 0.9431\n",
      "Testing accuracy:  0.9161\n"
     ]
    }
   ],
   "source": [
    "clf_tfidf = LogisticRegression(max_iter=1000, random_state=RANDOM_SEED)\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "tfidf_train_acc = accuracy_score(y_train, clf_tfidf.predict(X_train_tfidf))\n",
    "tfidf_test_acc = accuracy_score(y_test, clf_tfidf.predict(X_test_tfidf))\n",
    "\n",
    "print(\"=== TF-IDF + Logistic Regression ===\")\n",
    "print(f\"Training accuracy: {tfidf_train_acc:.4f}\")\n",
    "print(f\"Testing accuracy:  {tfidf_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Dictionary Size</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoW</td>\n",
       "      <td>61488</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>61488</td>\n",
       "      <td>0.9431</td>\n",
       "      <td>0.9161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Method  Dictionary Size Train Accuracy Test Accuracy\n",
       "0     BoW            61488         0.9779        0.9070\n",
       "1  TF-IDF            61488         0.9431        0.9161"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"Method\": [\"BoW\", \"TF-IDF\"],\n",
    "    \"Dictionary Size\": [len(bow_vocab), len(tfidf_vocab)],\n",
    "    \"Train Accuracy\": [f\"{bow_train_acc:.4f}\", f\"{tfidf_train_acc:.4f}\"],\n",
    "    \"Test Accuracy\": [f\"{bow_test_acc:.4f}\", f\"{tfidf_test_acc:.4f}\"],\n",
    "})\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hku-econ6087 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
